{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 450, 1: 358, 2: 154, 3: 30, 4: 6, 5: 2, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0}\n"
     ]
    }
   ],
   "source": [
    "# In this file, we'll explore some of the ways that p-values can me misinterpreted.  \n",
    "# Let's do linear regressions for random inputs and random outputs.\n",
    "\n",
    "covariates = 15\n",
    "samples = 100\n",
    "tests = 1000\n",
    "p_bound = .05\n",
    "reject_counts = {i:0 for i in range(covariates + 1)}\n",
    "\n",
    "for i in range(tests):\n",
    "    X = np.array([[random.random() for i in range(covariates + 1)] for j in range(samples)])\n",
    "    y = X[:,covariates]\n",
    "    count = 0\n",
    "    for j in range(covariates):\n",
    "        X_constants = sm.add_constant(X[:,j])\n",
    "        model_sm = sm.OLS(y, X_constants).fit()\n",
    "        p_values = model_sm.pvalues\n",
    "        if p_values[1] <= p_bound:\n",
    "            count += 1\n",
    "\n",
    "    reject_counts[count] += 1\n",
    "\n",
    "print(reject_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number associated to 0 is the number of times that the regressions correctly reject correlations amongst all variables. For 15 covariates, 100 samples, and 1000 tests, this should happen only about 463 times. So more than half of the time, we will be making false correlations, since we know everything is random! Conclusion: as you increase the number of covariates, you are more likely to make false correlations. The alpha error must be made smaller to compensate for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.463, 1: 0.366, 2: 0.135, 3: 0.031, 4: 0.005, 5: 0.001, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0}\n",
      "{0: 0.45, 1: 0.358, 2: 0.154, 3: 0.03, 4: 0.006, 5: 0.002, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Computes probabilities assuming that the alpha error is precisely the chance of false correlation for each covariate.\n",
    "# Reject_counts, covariates, and tests are defined in the previous cell.\n",
    "\n",
    "probabilities = {}\n",
    "\n",
    "for i in range(covariates + 1):\n",
    "    prob = (math.factorial(covariates) / (math.factorial(i) * math.factorial(covariates-i))) * (1-p_bound)**(covariates-i) * (p_bound)**(i)\n",
    "    probabilities[i] = round(prob, 3)\n",
    "\n",
    "print(probabilities)\n",
    "\n",
    "# Let's compare these probabilities to the probabilities we got experimentally.\n",
    "\n",
    "for i in range(covariates + 1):\n",
    "    reject_counts[i] = round(reject_counts[i]/tests, 3)\n",
    "\n",
    "print(reject_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we can change our bound on p-values to in order to ensure that we maintain an alpha error of less than .05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0034137129465903193\n"
     ]
    }
   ],
   "source": [
    "alpha = .05\n",
    "\n",
    "# We solve for the p_bound in the first term of the probability calculation above (the term for not rejecting the null hypothesis).\n",
    "p_bound = 1 - (1 - alpha)**(1/covariates)\n",
    "\n",
    "print(p_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 947, 1: 52, 2: 1, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0}\n"
     ]
    }
   ],
   "source": [
    "# Redoing the first cell, but with the newly computed p_bound.\n",
    "covariates = 15\n",
    "samples = 100\n",
    "tests = 1000\n",
    "reject_counts = {i:0 for i in range(covariates + 1)}\n",
    "\n",
    "for i in range(tests):\n",
    "    X = np.array([[random.random() for i in range(covariates + 1)] for j in range(samples)])\n",
    "    y = X[:,covariates]\n",
    "    count = 0\n",
    "    for j in range(covariates):\n",
    "        X_constants = sm.add_constant(X[:,j])\n",
    "        model_sm = sm.OLS(y, X_constants).fit()\n",
    "        p_values = model_sm.pvalues\n",
    "        if p_values[1] <= p_bound:\n",
    "            count += 1\n",
    "\n",
    "    reject_counts[count] += 1\n",
    "\n",
    "print(reject_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the null hypothesis is rejected much less often!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
